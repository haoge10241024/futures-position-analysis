#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœŸè´§æŒä»“åˆ†æç³»ç»Ÿ - äº‘ç«¯æ•°æ®è·å–æ¨¡å—
ä¸“é—¨è§£å†³Streamlit Cloudç¯å¢ƒä¸‹çš„æ•°æ®è·å–é—®é¢˜
ä½œè€…ï¼š7haoge
é‚®ç®±ï¼š953534947@qq.com
"""

import streamlit as st
import pandas as pd
import numpy as np
import requests
import time
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
import warnings
warnings.filterwarnings('ignore')

class CloudDataFetcher:
    """äº‘ç«¯æ•°æ®è·å–å™¨ - ä¸“é—¨å¤„ç†äº‘ç«¯ç¯å¢ƒçš„æ•°æ®è·å–é—®é¢˜"""
    
    def __init__(self):
        self.session = self.create_session()
        self.max_retries = 3
        self.timeout = 30
        self.delay_between_requests = 2  # è¯·æ±‚é—´éš”
        
    def create_session(self):
        """åˆ›å»ºä¼˜åŒ–çš„è¯·æ±‚ä¼šè¯"""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        })
        return session
    
    def safe_akshare_call(self, func, *args, **kwargs):
        """å®‰å…¨çš„akshareè°ƒç”¨ï¼ŒåŒ…å«é‡è¯•æœºåˆ¶"""
        for attempt in range(self.max_retries):
            try:
                # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                if attempt > 0:
                    time.sleep(self.delay_between_requests * attempt)
                
                result = func(*args, **kwargs)
                if result is not None:
                    return result
                    
            except Exception as e:
                error_msg = str(e)
                if attempt == self.max_retries - 1:
                    st.warning(f"æ•°æ®è·å–å¤±è´¥ (å°è¯• {attempt + 1}/{self.max_retries}): {error_msg}")
                else:
                    st.info(f"é‡è¯•ä¸­... (å°è¯• {attempt + 1}/{self.max_retries})")
                
                # ç‰¹å®šé”™è¯¯çš„å¤„ç†
                if "timeout" in error_msg.lower():
                    time.sleep(5)  # è¶…æ—¶é”™è¯¯ç­‰å¾…æ›´é•¿æ—¶é—´
                elif "rate limit" in error_msg.lower():
                    time.sleep(10)  # é¢‘ç‡é™åˆ¶ç­‰å¾…æ›´é•¿æ—¶é—´
                    
        return None
    
    def fetch_position_data_with_fallback(self, trade_date: str, progress_callback=None) -> bool:
        """è·å–æŒä»“æ•°æ®ï¼ŒåŒ…å«å¤‡ç”¨æ–¹æ¡ˆ"""
        
        # å°è¯•å¯¼å…¥akshare
        try:
            import akshare as ak
        except ImportError:
            st.error("akshareæœªå®‰è£…ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            return False
        
        success_count = 0
        total_exchanges = 5
        
        # äº¤æ˜“æ‰€é…ç½® - æŒ‰æˆåŠŸç‡æ’åº
        exchanges = [
            {
                "name": "å¤§å•†æ‰€",
                "func": ak.futures_dce_position_rank,
                "filename": "å¤§å•†æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date}
            },
            {
                "name": "ä¸­é‡‘æ‰€", 
                "func": ak.get_cffex_rank_table,
                "filename": "ä¸­é‡‘æ‰€æŒä»“.xlsx",
                "args": {"date": trade_date}
            },
            {
                "name": "éƒ‘å•†æ‰€",
                "func": ak.get_czce_rank_table,
                "filename": "éƒ‘å•†æ‰€æŒä»“.xlsx", 
                "args": {"date": trade_date}
            },
            {
                "name": "ä¸ŠæœŸæ‰€",
                "func": ak.get_shfe_rank_table,
                "filename": "ä¸ŠæœŸæ‰€æŒä»“.xlsx",
                "args": {"date": trade_date}
            },
            {
                "name": "å¹¿æœŸæ‰€",
                "func": ak.futures_gfex_position_rank,
                "filename": "å¹¿æœŸæ‰€æŒä»“.xlsx",
                "args": {"date": trade_date}
            }
        ]
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        data_dir = "data"
        os.makedirs(data_dir, exist_ok=True)
        
        for i, exchange in enumerate(exchanges):
            if progress_callback:
                progress = i / total_exchanges * 0.6
                progress_callback(f"æ­£åœ¨è·å– {exchange['name']} æ•°æ®...", progress)
            
            try:
                st.info(f"ğŸ”„ æ­£åœ¨è·å– {exchange['name']} æ•°æ®...")
                
                # ä½¿ç”¨å®‰å…¨è°ƒç”¨
                data_dict = self.safe_akshare_call(exchange['func'], **exchange['args'])
                
                if data_dict:
                    # ä¿å­˜æ•°æ®
                    save_path = os.path.join(data_dir, exchange['filename'])
                    with pd.ExcelWriter(save_path, engine='openpyxl') as writer:
                        for sheet_name, df in data_dict.items():
                            # æ¸…ç†sheetåç§°
                            clean_name = sheet_name[:31].replace("/", "-").replace("*", "")
                            df.to_excel(writer, sheet_name=clean_name, index=False)
                    
                    st.success(f"âœ… {exchange['name']} æ•°æ®è·å–æˆåŠŸ")
                    success_count += 1
                else:
                    st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥ï¼Œä½†ä¸å½±å“å…¶ä»–äº¤æ˜“æ‰€")
                    
            except Exception as e:
                st.warning(f"âš ï¸ {exchange['name']} æ•°æ®è·å–å¤±è´¥: {str(e)}")
                continue
            
            # æ·»åŠ è¯·æ±‚é—´éš”
            time.sleep(self.delay_between_requests)
        
        if progress_callback:
            progress_callback("æŒä»“æ•°æ®è·å–å®Œæˆ", 0.6)
        
        return success_count > 0
    
    def fetch_price_data_with_fallback(self, trade_date: str, progress_callback=None) -> pd.DataFrame:
        """è·å–æœŸè´§è¡Œæƒ…æ•°æ®ï¼ŒåŒ…å«å¤‡ç”¨æ–¹æ¡ˆ"""
        
        try:
            import akshare as ak
        except ImportError:
            st.error("akshareæœªå®‰è£…ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")
            return pd.DataFrame()
        
        price_exchanges = [
            {"market": "DCE", "name": "å¤§å•†æ‰€"},
            {"market": "CFFEX", "name": "ä¸­é‡‘æ‰€"},
            {"market": "CZCE", "name": "éƒ‘å•†æ‰€"},
            {"market": "SHFE", "name": "ä¸ŠæœŸæ‰€"},
        ]
        
        all_data = []
        
        for i, exchange in enumerate(price_exchanges):
            if progress_callback:
                progress = 0.6 + (i / len(price_exchanges)) * 0.2
                progress_callback(f"æ­£åœ¨è·å– {exchange['name']} è¡Œæƒ…æ•°æ®...", progress)
            
            try:
                st.info(f"ğŸ”„ æ­£åœ¨è·å– {exchange['name']} è¡Œæƒ…æ•°æ®...")
                
                # ä½¿ç”¨å®‰å…¨è°ƒç”¨
                df = self.safe_akshare_call(
                    ak.get_futures_daily,
                    start_date=trade_date,
                    end_date=trade_date,
                    market=exchange["market"]
                )
                
                if df is not None and not df.empty:
                    df['exchange'] = exchange["name"]
                    all_data.append(df)
                    st.success(f"âœ… {exchange['name']} è¡Œæƒ…æ•°æ®è·å–æˆåŠŸ")
                else:
                    st.warning(f"âš ï¸ {exchange['name']} è¡Œæƒ…æ•°æ®ä¸ºç©º")
                    
            except Exception as e:
                st.warning(f"âš ï¸ {exchange['name']} è¡Œæƒ…æ•°æ®è·å–å¤±è´¥: {str(e)}")
                continue
            
            # æ·»åŠ è¯·æ±‚é—´éš”
            time.sleep(self.delay_between_requests)
        
        if progress_callback:
            progress_callback("è¡Œæƒ…æ•°æ®è·å–å®Œæˆ", 0.8)
        
        return pd.concat(all_data, ignore_index=True) if all_data else pd.DataFrame()
    
    def create_demo_data(self, trade_date: str) -> bool:
        """åˆ›å»ºæ¼”ç¤ºæ•°æ®ï¼ˆå½“æ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥æ—¶ï¼‰"""
        st.warning("âš ï¸ æ‰€æœ‰æ•°æ®æºéƒ½æ— æ³•è®¿é—®ï¼Œæ­£åœ¨åˆ›å»ºæ¼”ç¤ºæ•°æ®...")
        
        data_dir = "data"
        os.makedirs(data_dir, exist_ok=True)
        
        # åˆ›å»ºæ¼”ç¤ºæŒä»“æ•°æ®
        demo_contracts = ['èºçº¹é’¢2501', 'é“çŸ¿çŸ³2501', 'è±†ç²•2501', 'ç‰ç±³2501', 'ç™½ç³–2501']
        
        for exchange_name in ['å¤§å•†æ‰€', 'ä¸­é‡‘æ‰€', 'éƒ‘å•†æ‰€', 'ä¸ŠæœŸæ‰€', 'å¹¿æœŸæ‰€']:
            filename = f"{exchange_name}æŒä»“.xlsx"
            save_path = os.path.join(data_dir, filename)
            
            # åˆ›å»ºæ¼”ç¤ºæ•°æ®
            demo_data = {}
            for contract in demo_contracts:
                # ç”Ÿæˆéšæœºä½†åˆç†çš„æŒä»“æ•°æ®
                np.random.seed(hash(contract + trade_date) % 2**32)
                
                data = []
                for i in range(20):  # å‰20å
                    data.append({
                        'long_party_name': f'æœŸè´§å…¬å¸{i+1}',
                        'long_open_interest': np.random.randint(1000, 50000),
                        'long_open_interest_chg': np.random.randint(-5000, 5000),
                        'short_party_name': f'æœŸè´§å…¬å¸{i+1}',
                        'short_open_interest': np.random.randint(1000, 50000),
                        'short_open_interest_chg': np.random.randint(-5000, 5000),
                    })
                
                demo_data[contract] = pd.DataFrame(data)
            
            # ä¿å­˜æ¼”ç¤ºæ•°æ®
            with pd.ExcelWriter(save_path, engine='openpyxl') as writer:
                for sheet_name, df in demo_data.items():
                    df.to_excel(writer, sheet_name=sheet_name, index=False)
        
        st.info("âœ… æ¼”ç¤ºæ•°æ®åˆ›å»ºå®Œæˆï¼Œæ‚¨å¯ä»¥ä½“éªŒç³»ç»ŸåŠŸèƒ½")
        return True
    
    def diagnose_network_issues(self):
        """è¯Šæ–­ç½‘ç»œé—®é¢˜"""
        st.subheader("ğŸ” ç½‘ç»œè¯Šæ–­")
        
        # æµ‹è¯•åŸºæœ¬ç½‘ç»œè¿æ¥
        test_urls = [
            ("ç™¾åº¦", "https://www.baidu.com"),
            ("æ–°æµª", "https://www.sina.com.cn"),
            ("akshareå®˜ç½‘", "https://akshare.akfamily.xyz")
        ]
        
        for name, url in test_urls:
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 200:
                    st.success(f"âœ… {name} è¿æ¥æ­£å¸¸")
                else:
                    st.warning(f"âš ï¸ {name} è¿æ¥å¼‚å¸¸ (çŠ¶æ€ç : {response.status_code})")
            except Exception as e:
                st.error(f"âŒ {name} è¿æ¥å¤±è´¥: {str(e)}")
        
        # æµ‹è¯•akshareå¯¼å…¥
        try:
            import akshare as ak
            st.success(f"âœ… akshare å¯¼å…¥æˆåŠŸ (ç‰ˆæœ¬: {getattr(ak, '__version__', 'æœªçŸ¥')})")
        except ImportError:
            st.error("âŒ akshare å¯¼å…¥å¤±è´¥")
        
        # æä¾›è§£å†³å»ºè®®
        st.markdown("""
        ### ğŸ’¡ è§£å†³å»ºè®®
        
        å¦‚æœæ•°æ®è·å–å¤±è´¥ï¼Œå¯èƒ½çš„åŸå› å’Œè§£å†³æ–¹æ¡ˆï¼š
        
        1. **ç½‘ç»œé™åˆ¶**: Streamlit Cloudå¯èƒ½é™åˆ¶æŸäº›å¤–éƒ¨APIè®¿é—®
           - è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨æ¼”ç¤ºæ•°æ®ä½“éªŒåŠŸèƒ½
        
        2. **APIé¢‘ç‡é™åˆ¶**: akshareçš„æ•°æ®æºå¯èƒ½æœ‰è®¿é—®é¢‘ç‡é™åˆ¶
           - è§£å†³æ–¹æ¡ˆ: ç­‰å¾…å‡ åˆ†é’Ÿåé‡è¯•
        
        3. **æ•°æ®æºç»´æŠ¤**: äº¤æ˜“æ‰€æ•°æ®æºå¯èƒ½åœ¨ç»´æŠ¤
           - è§£å†³æ–¹æ¡ˆ: é€‰æ‹©å…¶ä»–äº¤æ˜“æ—¥æœŸ
        
        4. **äº‘ç«¯ç¯å¢ƒé™åˆ¶**: æŸäº›äº‘ç«¯ç¯å¢ƒå¯¹å¤–éƒ¨è¯·æ±‚æœ‰é™åˆ¶
           - è§£å†³æ–¹æ¡ˆ: æœ¬åœ°è¿è¡Œæˆ–ä½¿ç”¨æ¼”ç¤ºæ¨¡å¼
        """)

# å…¨å±€å®ä¾‹
cloud_fetcher = CloudDataFetcher() 